{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm_notebook, tqdm\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "\n",
    "dtypes = {\n",
    "    'user':   'uint32',\n",
    "    'movie':  'uint16',\n",
    "    'rating': 'uint8'\n",
    "}\n",
    "\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бенчмарки\n",
    "В данной работе проводится сравнение работы Vowpall Wabbit и нашей FM на основе датасета MovieLens\n",
    "Будут проверены следующие модификации:\n",
    "- **movielens - 1m**  с нормализацией признаков\n",
    "- **movielens - 1m**  без нормализации признаков\n",
    "- **movielens - 10m** без нормализации признаков\n",
    "- **movielens - 10m** как задача классификации\n",
    "- **movielens - 20m** без нормализации признаков\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "### Предподготовка датасета в pandas\n",
    "\n",
    "**Основные паки признаков:**\n",
    "- OHE юзеров и фильмов\n",
    "- Время (число месяцев, прошедшее от первой записи)\n",
    "- OHE жанров фильмов\n",
    "- Признаки пользователей (только для ml-1m)\n",
    "- Факт оценивания фильма (OHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# построение различных признаков для movielens\n",
    "def build_movielens(folder, test_size, with_genres=True, with_users_info=True, with_rated_movies=True):\n",
    "    print('load ratings....')\n",
    "    rating_path = [name for name in os.listdir(folder) if 'ratings' in name][0]\n",
    "    ratings = pd.read_csv(folder + rating_path, sep='::', header=None, engine='python',\n",
    "                          names=['user', 'movie', 'rating', 'timestamp'], dtype=dtypes)\n",
    "\n",
    "    print('calculation of monthes....')\n",
    "    ratings['timestamp'] = pd.to_datetime(ratings.timestamp, unit='s')\n",
    "    min_date = ratings.timestamp.min()\n",
    "    ratings['monthes'] = (ratings.timestamp - min_date).dt.days // 28\n",
    "    ratings.monthes /= ratings.monthes.max()\n",
    "    ratings.monthes = ratings.monthes.astype('float16')\n",
    "    dataset = ratings.drop('timestamp', 1)\n",
    "    del(ratings); gc.collect()\n",
    "    \n",
    "    if with_genres and 'movies.dat' in os.listdir(folder):\n",
    "        print('load movies....')\n",
    "        movie_path = [name for name in os.listdir(folder) if 'movies' in name][0]\n",
    "        movies = pd.read_csv(folder + movie_path, sep='::', engine='python',\n",
    "                             names=['movie', 'title', 'genres'], \n",
    "                             usecols=['movie', 'genres'], header=None, dtype=dtypes)\n",
    "\n",
    "        print('build genres ohe....')\n",
    "        sparse_genres = CountVectorizer().fit_transform(movies.genres.map(lambda x: x.replace('|', ' ')))\n",
    "        colnames = ['genre_{}'.format(col) for col in range(sparse_genres.shape[1])]\n",
    "        sparse_genres = pd.DataFrame(sparse_genres.todense().astype('uint8'), columns=colnames)\n",
    "        movies = pd.concat([movies[['movie']], sparse_genres], axis=1)\n",
    "        del(sparse_genres); gc.collect()        \n",
    "\n",
    "        print('join dataframes....')\n",
    "        dataset = pd.merge(dataset, movies, on='movie', how='inner')\n",
    "        del(movies); gc.collect()\n",
    "    else:\n",
    "        print('genres skipped')\n",
    "    \n",
    "    if with_users_info and 'users.dat' in os.listdir(folder):\n",
    "        print('load users info....')\n",
    "        users = pd.read_csv(folder + 'users.dat', sep='::', \n",
    "                            header=None, names=['user', 'gender', 'age', 'occupation', 'zip'],\n",
    "                            engine='python')\n",
    "        users.age    = (users.age / users.age.max()).astype('float16')\n",
    "        users.gender = users.gender.apply(lambda x: 1 if x=='M' else 0).astype('int8')\n",
    "        users.occupation = users.occupation.astype('int8')\n",
    "        users.zip    = np.unique(users.zip.values, return_inverse=True)[1]\n",
    "        users.zip = users.zip.astype('int16')\n",
    "        dataset = pd.merge(dataset, users, on='user', how='left')\n",
    "        del(users); gc.collect()\n",
    "    else:\n",
    "        print('users info skipped')\n",
    "\n",
    "    np.random.seed(42)\n",
    "    print('train/test split...')\n",
    "    test_indexes = np.random.choice(dataset.index, int(test_size * dataset.shape[0]), replace=False)\n",
    "    test = dataset.loc[test_indexes]\n",
    "    train = dataset.drop(test_indexes)\n",
    "    del(dataset); gc.collect();\n",
    "    \n",
    "    if with_rated_movies:\n",
    "        print('building rated movies history (on train)....')\n",
    "        rated_movies = train.groupby('user')['movie'].agg(lambda x: list(x))\n",
    "        train.loc[:, 'ratedMovies'] = train.user.map(rated_movies)\n",
    "        test.loc[:, 'ratedMovies']  = test.user.map(rated_movies)\n",
    "        del(rated_movies); gc.collect()\n",
    "    else:\n",
    "        print('rated movies history skipped')\n",
    "        \n",
    "    print('preprocessing done....')\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "\n",
    "Используются для преведения полученного датасета в заданный формат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# хелпер для кодирования категориальных признаков\n",
    "def get_offset_stats(train, test):\n",
    "    offset_stats = {}\n",
    "    offset_stats['users_len']  = train.user.append(test.user).max() + 1#6040\n",
    "    offset_stats['movie_len'] = train.movie.append(test.movie).max() + 1 #3952\n",
    "    offset_stats['genre_len']  = len([col for col in train.columns if 'genre' in col])\n",
    "    if 'occupation' in train.columns:\n",
    "        offset_stats['occupation_len'] = train.occupation.append(test.occupation).max() + 1\n",
    "        offset_stats['zip_len']        = train.zip.append(test.zip).max() + 1\n",
    "    return offset_stats\n",
    "\n",
    "# функции, преобразующие датасет в формат, заданный feature_extractor\n",
    "def train2format(data, features_extractor, offset_lens, train='train',\n",
    "                 with_normalization=False,\n",
    "                 with_user_features=False,\n",
    "                 with_rated_films=False):\n",
    "    \n",
    "    writer_train      = open(train, 'w')    \n",
    "    for row in tqdm(data.iterrows(), total=data.shape[0], miniters=1000):\n",
    "        features = features_extractor(\n",
    "            row[1], offset_lens, with_normalization,\n",
    "            with_user_features, with_rated_films)\n",
    "        \n",
    "        label = str(int(row[1]['rating']))\n",
    "        output_line = '{0} {1}\\n'.format(label, features)\n",
    "        writer_train.write(output_line)            \n",
    "    writer_train.close()\n",
    "\n",
    "def test2format(data, features_extractor, offset_lens, \n",
    "                x_test_output='test', y_test_output='ytest', \n",
    "                with_normalization=False,\n",
    "                with_user_features=False,\n",
    "                with_rated_films=False):\n",
    "    \n",
    "    writer_test = open(x_test_output, 'w')\n",
    "    writer_ytest = open(y_test_output, 'w')\n",
    "    for row in tqdm(data.iterrows(), total=data.shape[0]):\n",
    "        label = str(int(row[1]['rating']))\n",
    "        features = features_extractor(\n",
    "            row[1], offset_lens, with_normalization,\n",
    "            with_user_features, with_rated_films)\n",
    "        \n",
    "        output_line = '{0} {1}\\n'.format(label, features)\n",
    "        writer_test.write(output_line)\n",
    "        writer_ytest.write('%s\\n' % label) \n",
    "    \n",
    "    writer_test.close()\n",
    "    writer_ytest.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractor\n",
    "Собственно обработка одной строчки датасета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fm_extractor(row, field_info, with_normalization=False, with_user_features=False, with_rated_films=False):\n",
    "    offset = 0\n",
    "    current_cat_value = ('{0:.2}'.format(1 / field_info['users_len']) if with_normalization else '1')\n",
    "    output_line = '{0}:{1} '.format(int(row['user']) + offset, current_cat_value)\n",
    "    \n",
    "    offset += field_info['users_len']\n",
    "    current_cat_value = ('{0:.2}'.format(1 / field_info['movie_len']) if with_normalization else '1')\n",
    "    output_line += '{0}:{1} '.format(int(row['movie']) + offset, current_cat_value)\n",
    "    \n",
    "    offset += field_info['movie_len']\n",
    "    output_line += '{0}:{1:.1} '.format(offset, row['monthes'])\n",
    "    \n",
    "    offset += 1\n",
    "    current_cat_value = ('{0:.2}'.format(1 / field_info['genre_len']) if with_normalization else '1')\n",
    "    for genre_index in range(field_info['genre_len']):\n",
    "        if row['genre_{}'.format(genre_index)] == 1:\n",
    "            output_line += '{0}:{1} '.format(offset + genre_index, current_cat_value)\n",
    "            \n",
    "    offset += field_info['genre_len']\n",
    "    if with_user_features:\n",
    "        output_line += '{0}:{1} '.format(offset, row['gender'])\n",
    "        offset += 1\n",
    "        output_line += '{0}:{1:.1} '.format(offset, row['age'])\n",
    "        offset += 1\n",
    "        \n",
    "        current_cat_value = ('{0:.2}'.format(1 / field_info['occupation_len']) if with_normalization else '1')\n",
    "        output_line += '{0}:{1} '.format(row['occupation'] + offset, current_cat_value)\n",
    "        offset += field_info['occupation_len']\n",
    "        \n",
    "        current_cat_value = ('{0:.2}'.format(1 / field_info['zip_len']) if with_normalization else '1')\n",
    "        output_line += '{0}:{1} '.format(row['zip'] + offset, current_cat_value)\n",
    "        offset += field_info['zip_len']\n",
    "    \n",
    "    if with_rated_films:\n",
    "        n_rated_movies = len(row['ratedMovies'])\n",
    "        for movie_id in row['ratedMovies']:\n",
    "            output_line += '{0}:{1:.3} '.format(movie_id + offset, 1 / n_rated_movies)\n",
    "        \n",
    "    return output_line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сonversion between vw/fm and regression/classification\n",
    "Хелперы для преобразования между vw / fm форматами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fm2vw(infile, outfile):    \n",
    "    input_file = open(infile,  'r')\n",
    "    out_file   = open(outfile, 'w')\n",
    "    for line in tqdm(input_file):\n",
    "        out_file.write(line[0] + ' |' + line[1:])\n",
    "\n",
    "def reg2fm(infile, outfile):    \n",
    "    input_file = open(infile,  'r')\n",
    "    out_file   = open(outfile, 'w')\n",
    "    for line in tqdm(input_file):\n",
    "        target = str(int(int(line[0]) > 3))\n",
    "        out_file.write(target + line[1:])\n",
    "\n",
    "def reg2vw(infile, outfile):    \n",
    "    input_file = open(infile,  'r')\n",
    "    out_file   = open(outfile, 'w')\n",
    "    for line in tqdm(input_file):\n",
    "        target = str((int(line[0]) > 3) * 2 - 1)\n",
    "        out_file.write(target + ' |' + line[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inplace metrics\n",
    "\n",
    "Функции, позволяющие оценить те или иные метрики, не загружаю в память таблички"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rmse(ytest_input='ytest', pred_input='pred'):\n",
    "    n, loss = 0, 0\n",
    "    reader_ytest = open(ytest_input, 'r')\n",
    "    reader_pred = open(pred_input, 'r')\n",
    "\n",
    "    for label, pred in zip(reader_ytest, reader_pred):    \n",
    "        n+=1\n",
    "        true_score = float(label)\n",
    "        pred_score = float(pred)\n",
    "        loss += np.square(pred_score - true_score)\n",
    "    reader_ytest.close()\n",
    "    reader_pred.close()\n",
    "    return np.sqrt(loss / n)\n",
    "\n",
    "def get_log_loss(ytest_input='ytest', pred_input='pred'):\n",
    "    n, loss = 0, 0\n",
    "    reader_ytest = open(ytest_input, 'r')\n",
    "    reader_pred = open(pred_input, 'r')\n",
    "\n",
    "    for label, pred in zip(reader_ytest, reader_pred):    \n",
    "        n+=1        \n",
    "        true_label = int(label)\n",
    "        pred_score = float(pred)\n",
    "        loss -= true_label * np.log(pred_score) + (1 - true_label) * np.log(1 - pred_score) \n",
    "        \n",
    "    reader_ytest.close()\n",
    "    reader_pred.close()\n",
    "    return loss / n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "\n",
    "Попробуем для начала на датасете ml-1m, используя нормализацию и все полученные фичи, кроме ratedMovies\n",
    "\n",
    "Чуть позже же решим, делает ли нам нормализация категориальных признаков хорошо или нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ratings....\n",
      "calculation of monthes....\n",
      "load movies....\n",
      "build genres ohe....\n",
      "join dataframes....\n",
      "load users info....\n",
      "train/test split...\n",
      "building rated movies history (on train)....\n",
      "preprocessing done....\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>monthes</th>\n",
       "      <th>genre_0</th>\n",
       "      <th>genre_1</th>\n",
       "      <th>genre_2</th>\n",
       "      <th>genre_3</th>\n",
       "      <th>genre_4</th>\n",
       "      <th>genre_5</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_15</th>\n",
       "      <th>genre_16</th>\n",
       "      <th>genre_17</th>\n",
       "      <th>genre_18</th>\n",
       "      <th>genre_19</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>occupation</th>\n",
       "      <th>zip</th>\n",
       "      <th>ratedMovies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>0.216187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16</td>\n",
       "      <td>2248</td>\n",
       "      <td>[1193, 3105, 2321, 1962, 1207, 2028, 1246, 306...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>0.216187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.446533</td>\n",
       "      <td>12</td>\n",
       "      <td>1165</td>\n",
       "      <td>[1193, 2804, 1198, 593, 1247, 1641, 1221, 111,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>0.216187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.446533</td>\n",
       "      <td>7</td>\n",
       "      <td>904</td>\n",
       "      <td>[1193, 3408, 3105, 2321, 527, 2762, 260, 2028,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>0.216187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.893066</td>\n",
       "      <td>1</td>\n",
       "      <td>3187</td>\n",
       "      <td>[1193, 595, 2321, 720, 1270, 527, 1097, 2762, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>1193</td>\n",
       "      <td>4</td>\n",
       "      <td>0.216187</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.321533</td>\n",
       "      <td>3</td>\n",
       "      <td>3227</td>\n",
       "      <td>[1193, 1197, 919, 595, 2018, 2797, 527, 48, 10...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  movie  rating   monthes  genre_0  genre_1  genre_2  genre_3  genre_4  \\\n",
       "1     2   1193       5  0.216187        0        0        0        0        0   \n",
       "2    12   1193       4  0.216187        0        0        0        0        0   \n",
       "3    15   1193       4  0.216187        0        0        0        0        0   \n",
       "4    17   1193       5  0.216187        0        0        0        0        0   \n",
       "5    18   1193       4  0.216187        0        0        0        0        0   \n",
       "\n",
       "   genre_5                        ...                          genre_15  \\\n",
       "1        0                        ...                                 0   \n",
       "2        0                        ...                                 0   \n",
       "3        0                        ...                                 0   \n",
       "4        0                        ...                                 0   \n",
       "5        0                        ...                                 0   \n",
       "\n",
       "   genre_16  genre_17  genre_18  genre_19  gender       age  occupation   zip  \\\n",
       "1         0         0         0         0       1  1.000000          16  2248   \n",
       "2         0         0         0         0       1  0.446533          12  1165   \n",
       "3         0         0         0         0       1  0.446533           7   904   \n",
       "4         0         0         0         0       1  0.893066           1  3187   \n",
       "5         0         0         0         0       0  0.321533           3  3227   \n",
       "\n",
       "                                         ratedMovies  \n",
       "1  [1193, 3105, 2321, 1962, 1207, 2028, 1246, 306...  \n",
       "2  [1193, 2804, 1198, 593, 1247, 1641, 1221, 111,...  \n",
       "3  [1193, 3408, 3105, 2321, 527, 2762, 260, 2028,...  \n",
       "4  [1193, 595, 2321, 720, 1270, 527, 1097, 2762, ...  \n",
       "5  [1193, 1197, 919, 595, 2018, 2797, 527, 48, 10...  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = 'SourceData/ml-1m/'\n",
    "test_size = 0.25\n",
    "train, test = build_movielens(folder, test_size)\n",
    "field_info = get_offset_stats(train, test)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750157/750157 [07:11<00:00, 1738.67it/s]\n",
      "100%|██████████| 250052/250052 [02:41<00:00, 1551.64it/s]\n"
     ]
    }
   ],
   "source": [
    "train2format(train, fm_extractor, field_info, 'Generated/train_1m_norm_user_reg.fm',\n",
    "             with_normalization=True, with_user_features=True)\n",
    "test2format(test, fm_extractor, field_info, 'Generated/test_1m_norm_user_reg.fm', 'Generated/ytest_1m_norm_user_reg', \n",
    "            with_normalization=True, with_user_features=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Для начала посмотрим, как же пользоваться этой нашей тулзой"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library for using factorization algorithm\n",
      "Usage:\n",
      "  Factorization machines [OPTION...]\n",
      "\n",
      "  -l, --learning_rate arg       Learning rate value, default 0.1\n",
      "      --bias                    Use bias or not\n",
      "      --linear                  Use linear or not\n",
      "      --pairwise arg            Two-way interactions order\n",
      "  -r, --regularization_const arg\n",
      "                                Regularization constant, default 0\n",
      "  -i, --iterations arg          Number of iterations, default 100\n",
      "  -m, --learning_method arg     Learning method (SGD, ALS), default SGD\n",
      "  -g, --inplace arg             Storage (inplace, memory), default memory\n",
      "  -t, --train_filename arg      Training file name\n",
      "  -e, --test_filename arg       Testing file name\n",
      "  -s, --task_type arg           Task type parameter\n",
      "      --hash_size arg           Positive hash size if use hashing trick, else\n",
      "                                -1, default -1\n",
      "      --hash_random_seed arg    Random seed of hashing\n",
      "  -h, --help                    Usage description\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!./FM --help"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Жадный поиск гиперпараметров\n",
    "\n",
    "Начнем жадно подбирать параметры для SGD и ALD независимо. Начнем со старого доброго **SGD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=1.24986 Test=1.25241\n",
      "iter=1 Train=1.24717 Test=1.24976\n",
      "iter=2 Train=1.24731 Test=1.24994\n",
      "iter=3 Train=1.2479 Test=1.25057\n",
      "iter=4 Train=1.24863 Test=1.25135\n",
      "Time:\t\t215 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_1m_norm_user_reg.fm -e Generated/test_1m_norm_user_reg.fm \\\n",
    "    --learning_rate 0.0001 --learning_method SGD --hash_size -1 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=1.2283 Test=1.23035\n",
      "iter=1 Train=1.19918 Test=1.20147\n",
      "iter=2 Train=1.19037 Test=1.19275\n",
      "iter=3 Train=1.18601 Test=1.18845\n",
      "iter=4 Train=1.1833 Test=1.18577\n",
      "Time:\t\t255 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_1m_norm_user_reg.fm -e Generated/test_1m_norm_user_reg.fm \\\n",
    "    --learning_rate 0.00001 --learning_method SGD --hash_size -1 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=1.22793 Test=1.22998\n",
      "iter=1 Train=1.19955 Test=1.20183\n",
      "iter=2 Train=1.19078 Test=1.19316\n",
      "iter=3 Train=1.18639 Test=1.18882\n",
      "iter=4 Train=1.18362 Test=1.18608\n",
      "Time:\t\t136 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --pairwise 0 --task_type regression -t Generated/train_1m_norm_user_reg.fm -e Generated/test_1m_norm_user_reg.fm \\\n",
    "    --learning_rate 0.00001 --learning_method SGD --hash_size -1 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=1.57304 Test=1.57461\n",
      "iter=1 Train=1.29849 Test=1.29996\n",
      "iter=2 Train=1.2531 Test=1.25456\n",
      "iter=3 Train=1.23133 Test=1.23285\n",
      "iter=4 Train=1.21515 Test=1.21673\n",
      "Time:\t\t219 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_1m_norm_user_reg.fm -e Generated/test_1m_norm_user_reg.fm \\\n",
    "    --learning_rate 0.000001 --learning_method SGD --hash_size -1 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=1.57427 Test=1.57586\n",
      "iter=1 Train=1.29442 Test=1.29592\n",
      "iter=2 Train=1.24919 Test=1.25068\n",
      "iter=3 Train=1.22833 Test=1.22986\n",
      "iter=4 Train=1.21293 Test=1.21453\n",
      "Time:\t\t127 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --pairwise 0 --task_type regression -t Generated/train_1m_norm_user_reg.fm -e Generated/test_1m_norm_user_reg.fm \\\n",
    "    --learning_rate 0.000001 --learning_method SGD --hash_size -1 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=1.23412 Test=1.23618\n",
      "iter=1 Train=1.20378 Test=1.20607\n",
      "iter=2 Train=1.19402 Test=1.19641\n",
      "iter=3 Train=1.18942 Test=1.19184\n",
      "iter=4 Train=1.18681 Test=1.18926\n",
      "Time:\t\t182 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_1m_norm_user_reg.fm -e Generated/test_1m_norm_user_reg.fm \\\n",
    "    --learning_rate 0.00001 --regularization_const 0.01 --learning_method SGD --hash_size -1 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лучший SGD набирает порядка 1.18 RMSE на отложенной выборке**\n",
    "\n",
    "### ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=0.883127 Test=0.925434\n",
      "iter=1 Train=0.863028 Test=0.923017\n",
      "iter=2 Train=0.849879 Test=0.919942\n",
      "iter=3 Train=0.840508 Test=0.915377\n",
      "iter=4 Train=0.834058 Test=0.911848\n",
      "Time:\t\t859 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_1m_norm_user_reg.fm -e Generated/test_1m_norm_user_reg.fm \\\n",
    "    --learning_method ALS --hash_size -1 -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=0.904478 Test=0.920831\n",
      "iter=1 Train=0.895432 Test=0.911426\n",
      "iter=2 Train=0.894925 Test=0.910885\n",
      "iter=3 Train=0.894861 Test=0.910814\n",
      "iter=4 Train=0.894837 Test=0.910785\n",
      "Time:\t\t165 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --pairwise 0 --task_type regression -t Generated/train_1m_norm_user_reg.fm -e Generated/test_1m_norm_user_reg.fm \\\n",
    "    --learning_method ALS --hash_size -1 -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=0.937126 Test=0.94576\n",
      "iter=1 Train=0.935544 Test=0.943866\n",
      "iter=2 Train=0.93519 Test=0.943468\n",
      "iter=3 Train=0.934827 Test=0.943097\n",
      "iter=4 Train=0.934496 Test=0.942765\n",
      "Time:\t\t161 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --pairwise 0 --task_type regression -t Generated/train_1m_norm_user_reg.fm -e Generated/test_1m_norm_user_reg.fm \\\n",
    "    --learning_method ALS --regularization_const 0.00001 --hash_size -1 -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лучший скор - 0.910**\n",
    "\n",
    "**ALS результаты и вовсе внушительные, причем наличие парных взаимодействий на данном датасете на эффективность особо не влияет**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VW\n",
    "### Приведем наши датасеты к формату VW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "750157it [00:01, 673301.96it/s]\n",
      "250052it [00:00, 718377.71it/s]\n"
     ]
    }
   ],
   "source": [
    "fm2vw('Generated/train_1m_norm_user_reg.fm', 'Generated/train_1m_norm_user_reg.vw')\n",
    "fm2vw('Generated/test_1m_norm_user_reg.fm', 'Generated/test_1m_norm_user_reg.vw')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### И снова как мы любим начнем жадно выбирать параметры\n",
    "\n",
    "Начнем с SGD и найдем хороший learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done - 4 seconds\n",
      "Start evaluation\n",
      "Validation RMSE:\t 1.198904507129869\n",
      "Time:\t\t6 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_1m_norm_user_reg.vw -f VwHelpFiles/model --loss_function squared --sgd --learning_rate 0.01 -b 14 --passes 5 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_1m_norm_user_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_norm_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done - 4 seconds\n",
      "Start evaluation\n",
      "Validation RMSE:\t 1.1675452150871288\n",
      "Time:\t\t6 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_1m_norm_user_reg.vw -f VwHelpFiles/model --loss_function squared --sgd --learning_rate 0.001 -b 14 --passes 5 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_1m_norm_user_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_norm_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done - 4 seconds\n",
      "Start evaluation\n",
      "Validation RMSE:\t 1.5458927830958853\n",
      "Time:\t\t6 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_1m_norm_user_reg.vw -f VwHelpFiles/model --loss_function squared --sgd --learning_rate 0.0001 -b 14 --passes 5 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_1m_norm_user_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_norm_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Число проходов\n",
    "\n",
    "Для лучшей конфигуразции будем увеличивать число проходов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done - 8 seconds\n",
      "Start evaluation\n",
      "Validation RMSE:\t 1.1483929069769112\n",
      "Time:\t\t10 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_1m_norm_user_reg.vw -f VwHelpFiles/model --loss_function squared --sgd --learning_rate 0.001 -b 14 --passes 10 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_1m_norm_user_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_norm_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done - 15 seconds\n",
      "Start evaluation\n",
      "Validation RMSE:\t 1.1354925339260975\n",
      "Time:\t\t18 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_1m_norm_user_reg.vw -f VwHelpFiles/model --loss_function squared --sgd --learning_rate 0.001 -b 14 --passes 20 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_1m_norm_user_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_norm_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done - 31 seconds\n",
      "Start evaluation\n",
      "Validation RMSE:\t 1.1269815304667365\n",
      "Time:\t\t33 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_1m_norm_user_reg.vw -f VwHelpFiles/model --loss_function squared --sgd --learning_rate 0.001 -b 14 --passes 40 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_1m_norm_user_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_norm_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done - 62 seconds\n",
      "Start evaluation\n",
      "Validation RMSE:\t 1.1224261716600354\n",
      "Time:\t\t64 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_1m_norm_user_reg.vw -f VwHelpFiles/model --loss_function squared --sgd --learning_rate 0.001 -b 14 --passes 80 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_1m_norm_user_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_norm_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лучший результат на VW SGD - 1.1224**\n",
    "\n",
    "Попробуем на хитрых дефолтных параметрах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done - 4 seconds\n",
      "Start evaluation\n",
      "Validation RMSE:\t 1.397999386906915\n",
      "Time:\t\t6 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_1m_norm_user_reg.vw -f VwHelpFiles/model --loss_function squared --learning_rate 0.001 -b 14 --passes 5 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_1m_norm_user_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_norm_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done - 4 seconds\n",
      "Start evaluation\n",
      "Validation RMSE:\t 1.068677025561811\n",
      "Time:\t\t6 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_1m_norm_user_reg.vw -f VwHelpFiles/model --loss_function squared --learning_rate 0.01 -b 14 --passes 5 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_1m_norm_user_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_norm_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done - 70 seconds\n",
      "Start evaluation\n",
      "Validation RMSE:\t 0.9439532525754946\n",
      "Time:\t\t72 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_1m_norm_user_reg.vw -f VwHelpFiles/model --loss_function squared --learning_rate 0.01 -b 14 --passes 80 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_1m_norm_user_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_norm_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лучший результат на VW - 0.944**\n",
    "\n",
    "Напомню, что лучший скор нашей тулзы был 0.910\n",
    "\n",
    "**И хотя какой-то хороший бейзлайн на VW получается довольно шустро, такого же качества, которое давал нам ALS добиться на VW не удалось**\n",
    "\n",
    "\n",
    "# Ненормированные ml-1m\n",
    "Посмотрим как себя поведут утилиты на ненормированных признаках"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750157/750157 [05:15<00:00, 2378.11it/s]\n",
      "100%|██████████| 250052/250052 [01:51<00:00, 2241.35it/s]\n"
     ]
    }
   ],
   "source": [
    "train2format(train, fm_extractor, field_info, 'Generated/train_1m_user_reg.fm',\n",
    "             with_normalization=False, with_user_features=True)\n",
    "test2format(test, fm_extractor, field_info, 'Generated/test_1m_user_reg.fm', 'Generated/ytest_1m_user_reg', \n",
    "            with_normalization=False, with_user_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=1.16565 Test=1.17666\n",
      "iter=1 Train=1.12185 Test=1.13626\n",
      "iter=2 Train=1.10682 Test=1.12384\n",
      "iter=3 Train=1.10884 Test=1.12796\n",
      "iter=4 Train=1.11811 Test=1.13904\n",
      "Time:\t\t215 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_1m_user_reg.fm -e Generated/test_1m_user_reg.fm \\\n",
    "    --learning_rate 0.01 --learning_method SGD --hash_size -1 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавим регуляризацию\n",
    "\n",
    "Как видим есть риск сильно перестараться"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=1.81831 Test=1.81998\n",
      "iter=1 Train=1.80246 Test=1.80387\n",
      "iter=2 Train=1.80235 Test=1.80342\n",
      "iter=3 Train=1.80293 Test=1.80416\n",
      "iter=4 Train=1.80428 Test=1.80517\n",
      "Time:\t\t213 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_1m_user_reg.fm -e Generated/test_1m_user_reg.fm  \\\n",
    "    --learning_rate 0.01 --learning_method SGD --regularization_const 0.1 --hash_size -1 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=1.07767 Test=1.08947\n",
      "iter=1 Train=1.01272 Test=1.02826\n",
      "iter=2 Train=0.987602 Test=1.00637\n",
      "iter=3 Train=0.986864 Test=1.00808\n",
      "iter=4 Train=0.997491 Test=1.02045\n",
      "Time:\t\t214 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_1m_user_reg.fm -e Generated/test_1m_user_reg.fm \\\n",
    "    --learning_rate 0.01 --learning_method SGD --regularization_const 0.01 --hash_size -1 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=1.15296 Test=1.16405\n",
      "iter=1 Train=1.10143 Test=1.11605\n",
      "iter=2 Train=1.07779 Test=1.09532\n",
      "iter=3 Train=1.07129 Test=1.09123\n",
      "iter=4 Train=1.07314 Test=1.09513\n",
      "Time:\t\t219 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_1m_user_reg.fm -e Generated/test_1m_user_reg.fm \\\n",
    "    --learning_rate 0.01 --learning_method SGD --regularization_const 0.001 --hash_size -1 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=1.2642 Test=1.26991\n",
      "iter=1 Train=1.21977 Test=1.22678\n",
      "iter=2 Train=1.18414 Test=1.19214\n",
      "iter=3 Train=1.15348 Test=1.16238\n",
      "iter=4 Train=1.12807 Test=1.13787\n",
      "Time:\t\t214 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_1m_user_reg.fm -e Generated/test_1m_user_reg.fm \\\n",
    "    --learning_rate 0.001 --learning_method SGD --regularization_const 0.001 --hash_size -1 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавим итераций лучшему алгоритму"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=1.19262 Test=1.19966\n",
      "iter=1 Train=1.13433 Test=1.14319\n",
      "iter=2 Train=1.09052 Test=1.10094\n",
      "iter=3 Train=1.05602 Test=1.06792\n",
      "iter=4 Train=1.02983 Test=1.04315\n",
      "iter=5 Train=1.01051 Test=1.02516\n",
      "iter=6 Train=0.996751 Test=1.01261\n",
      "iter=7 Train=0.987356 Test=1.00432\n",
      "iter=8 Train=0.981408 Test=0.999345\n",
      "iter=9 Train=0.978387 Test=0.997183\n",
      "Time:\t\t389 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_1m_user_reg.fm -e Generated/test_1m_user_reg.fm \\\n",
    "    --learning_rate 0.002 --learning_method SGD --regularization_const 0.01 --hash_size -1 -g inplace -i 10\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лучший результат нашей тулзы на SGD показал 0.997 RMSE на отложенной выборке**\n",
    "### ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=0.864562 Test=0.917794\n",
      "iter=1 Train=0.836503 Test=0.904523\n",
      "iter=2 Train=0.822554 Test=0.896032\n",
      "iter=3 Train=0.815551 Test=0.891903\n",
      "iter=4 Train=0.811589 Test=0.889514\n",
      "Time:\t\t781 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_1m_user_reg.fm -e Generated/test_1m_user_reg.fm \\\n",
    "    --learning_method ALS --hash_size -1 -g memory -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=0.904478 Test=0.920831\n",
      "iter=1 Train=0.895432 Test=0.911426\n",
      "iter=2 Train=0.894925 Test=0.910885\n",
      "iter=3 Train=0.894861 Test=0.910814\n",
      "iter=4 Train=0.894837 Test=0.910785\n",
      "Time:\t\t164 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --pairwise 0 --task_type regression -t Generated/train_1m_user_reg.fm -e Generated/test_1m_user_reg.fm \\\n",
    "    --learning_method ALS --hash_size -1 -g memory -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Обращаю внимание какой хороший эффект дают парные фичи, но при этом сильно замедляя работу**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=0.904478 Test=0.920826\n",
      "iter=1 Train=0.895433 Test=0.911422\n",
      "iter=2 Train=0.894925 Test=0.910881\n",
      "iter=3 Train=0.894861 Test=0.910809\n",
      "iter=4 Train=0.894837 Test=0.91078\n",
      "Time:\t\t157 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --pairwise 0 --task_type regression -t Generated/train_1m_user_reg.fm -e Generated/test_1m_user_reg.fm \\\n",
    "    --learning_method ALS --regularization_const 0.01 --hash_size -1 -g memory -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=0.904478 Test=0.92083\n",
      "iter=1 Train=0.895432 Test=0.911426\n",
      "iter=2 Train=0.894925 Test=0.910885\n",
      "iter=3 Train=0.894861 Test=0.910813\n",
      "iter=4 Train=0.894837 Test=0.910784\n",
      "Time:\t\t160 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --pairwise 0 --task_type regression -t Generated/train_1m_user_reg.fm -e Generated/test_1m_user_reg.fm \\\n",
    "    --learning_method ALS --regularization_const 0.001 --hash_size -1 -g memory -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=0.904478 Test=0.92083\n",
      "iter=1 Train=0.895432 Test=0.911426\n",
      "Time:\t\t75 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --pairwise 0 --task_type regression -t Generated/train_1m_user_reg.fm -e Generated/test_1m_user_reg.fm \\\n",
    "    --learning_method ALS --regularization_const 0.001 --hash_size -1 -g memory -i 2\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 750157 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "Preprocessing\n",
      "Processed 250052 rows\n",
      "Target from 1 to 5\n",
      "Max feature index is 13476\n",
      "iter=0 Train=0.864562 Test=0.917794\n",
      "iter=1 Train=0.836503 Test=0.904523\n",
      "iter=2 Train=0.822554 Test=0.896032\n",
      "iter=3 Train=0.815551 Test=0.891903\n",
      "iter=4 Train=0.811589 Test=0.889514\n",
      "iter=5 Train=0.809086 Test=0.88802\n",
      "iter=6 Train=0.807374 Test=0.887033\n",
      "iter=7 Train=0.806132 Test=0.886277\n",
      "iter=8 Train=0.805194 Test=0.885726\n",
      "iter=9 Train=0.804467 Test=0.885303\n",
      "Time:\t\t1844 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_1m_user_reg.fm -e Generated/test_1m_user_reg.fm \\\n",
    "    --learning_method ALS --hash_size -1 -g memory -i 10\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Итого лучший ALS с 10 проходами и 4 компонентами на парные взаимодействия показал 0.885 RMSE, обучаясь порядка 30 минут**\n",
    "\n",
    "**Результат 0.91 же мог быть достигнут и без парных взаимодействий за 2 прохода достаточно шустро**\n",
    "\n",
    "## Vowpal wabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "750157it [00:00, 915839.16it/s]\n",
      "250052it [00:00, 799685.63it/s]\n"
     ]
    }
   ],
   "source": [
    "fm2vw('Generated/train_1m_user_reg.fm', 'Generated/train_1m_user_reg.vw')\n",
    "fm2vw('Generated/test_1m_user_reg.fm', 'Generated/test_1m_user_reg.vw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done - 4 seconds\n",
      "Start evaluation\n",
      "Validation RMSE:\t 1.1573913484777147\n",
      "Time:\t\t6 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_1m_user_reg.vw -f VwHelpFiles/model --loss_function squared --sgd --learning_rate 0.001 -b 14 --passes 5 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_1m_user_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done - 8 seconds\n",
      "Start evaluation\n",
      "Validation RMSE:\t 1.139532181507997\n",
      "Time:\t\t10 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_1m_user_reg.vw -f VwHelpFiles/model --loss_function squared --sgd --learning_rate 0.001 -b 14 --passes 10 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_1m_user_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done - 16 seconds\n",
      "Start evaluation\n",
      "Validation RMSE:\t 1.1276584044115077\n",
      "Time:\t\t19 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_1m_user_reg.vw -f VwHelpFiles/model --loss_function squared --sgd --learning_rate 0.001 -b 14 --passes 20 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_1m_user_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done - 69 seconds\n",
      "Start evaluation\n",
      "Validation RMSE:\t 1.1148919874990038\n",
      "Time:\t\t71 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_1m_user_reg.vw -f VwHelpFiles/model --loss_function squared --sgd --learning_rate 0.001 -b 14 --passes 80 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_1m_user_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done - 43 seconds\n",
      "Start evaluation\n",
      "Validation RMSE:\t 1.109155811552204\n",
      "Time:\t\t45 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_1m_user_reg.vw -f VwHelpFiles/model --loss_function squared --sgd --learning_rate 0.002 -b 14 --passes 80 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_1m_user_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training done - 4 seconds\n",
      "Start evaluation\n",
      "Validation RMSE:\t 3.207281084486174\n",
      "Time:\t\t6 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_1m_user_reg.vw -f VwHelpFiles/model --loss_function squared  --l2 0.1 -b 14 --passes 20 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_1m_user_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Лучший VW дал 1.109, что серьезно уступает SGD режиму FM**\n",
    "\n",
    "**ALS режим же на данном датасете вообще из другой лиги**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Ненормированный ml-10M100K\n",
    "\n",
    "Сегодня мы многое поняли - например то, что нормировка не бог весть какая хорошая идея.\n",
    "\n",
    "Так что в дальнейшем будем рассматривать ненормированные датасеты.\n",
    "\n",
    "Более того, информация о пользователям нам уже не дана, так что эти фичи исключаются тоже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load ratings....\n",
      "calculation of monthes....\n",
      "load movies....\n",
      "build genres ohe....\n",
      "join dataframes....\n",
      "users info skipped\n",
      "train/test split...\n",
      "rated movies history skipped\n",
      "preprocessing done....\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>movie</th>\n",
       "      <th>rating</th>\n",
       "      <th>monthes</th>\n",
       "      <th>genre_0</th>\n",
       "      <th>genre_1</th>\n",
       "      <th>genre_2</th>\n",
       "      <th>genre_3</th>\n",
       "      <th>genre_4</th>\n",
       "      <th>genre_5</th>\n",
       "      <th>...</th>\n",
       "      <th>genre_14</th>\n",
       "      <th>genre_15</th>\n",
       "      <th>genre_16</th>\n",
       "      <th>genre_17</th>\n",
       "      <th>genre_18</th>\n",
       "      <th>genre_19</th>\n",
       "      <th>genre_20</th>\n",
       "      <th>genre_21</th>\n",
       "      <th>genre_22</th>\n",
       "      <th>genre_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.417480</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>215</td>\n",
       "      <td>122</td>\n",
       "      <td>4</td>\n",
       "      <td>0.708984</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>217</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.120850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>281</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.120850</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>326</td>\n",
       "      <td>122</td>\n",
       "      <td>3</td>\n",
       "      <td>0.109863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   user  movie  rating   monthes  genre_0  genre_1  genre_2  genre_3  genre_4  \\\n",
       "1   139    122       3  0.417480        0        0        0        0        1   \n",
       "4   215    122       4  0.708984        0        0        0        0        1   \n",
       "5   217    122       3  0.120850        0        0        0        0        1   \n",
       "6   281    122       3  0.120850        0        0        0        0        1   \n",
       "7   326    122       3  0.109863        0        0        0        0        1   \n",
       "\n",
       "   genre_5    ...     genre_14  genre_15  genre_16  genre_17  genre_18  \\\n",
       "1        0    ...            0         0         0         0         0   \n",
       "4        0    ...            0         0         0         0         0   \n",
       "5        0    ...            0         0         0         0         0   \n",
       "6        0    ...            0         0         0         0         0   \n",
       "7        0    ...            0         0         0         0         0   \n",
       "\n",
       "   genre_19  genre_20  genre_21  genre_22  genre_23  \n",
       "1         1         0         0         0         0  \n",
       "4         1         0         0         0         0  \n",
       "5         1         0         0         0         0  \n",
       "6         1         0         0         0         0  \n",
       "7         1         0         0         0         0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = 'SourceData/ml-10M100K/'\n",
    "test_size = 0.25\n",
    "train, test = build_movielens(\n",
    "    folder, test_size, with_genres=True,\n",
    "    with_users_info=False, with_rated_movies=False)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7500041/7500041 [38:31<00:00, 3245.04it/s]\n",
      "100%|██████████| 2500013/2500013 [12:24<00:00, 3357.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 139:1 71690:1 136702:0.4 136707:1 136722:1 \n",
      "4 215:1 71690:1 136702:0.7 136707:1 136722:1 \n",
      "3 217:1 71690:1 136702:0.1 136707:1 136722:1 \n"
     ]
    }
   ],
   "source": [
    "field_info = get_offset_stats(train, test)\n",
    "train2format(train, fm_extractor, field_info, 'Generated/train_10m_reg.fm',)\n",
    "test2format(\n",
    "    test, fm_extractor, field_info,\n",
    "    'Generated/test_10m_reg.fm',\n",
    "    'Generated/ytest_10m_reg'\n",
    ")\n",
    "!head -n 3 Generated/train_10m_reg.fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Найдем порядок хорошего learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 7500041 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 136726\n",
      "Preprocessing\n",
      "Processed 2500013 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 136726\n",
      "iter=0 Train=1.14542 Test=1.14962\n",
      "iter=1 Train=1.09418 Test=1.10123\n",
      "iter=2 Train=1.07929 Test=1.08916\n",
      "iter=3 Train=1.07324 Test=1.08581\n",
      "iter=4 Train=1.07011 Test=1.08503\n",
      "Time:\t\t1230 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_10m_reg.fm -e Generated/test_10m_reg.fm \\\n",
    "    --learning_rate 0.01 --learning_method SGD --hash_size -1 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 7500041 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 136726\n",
      "Preprocessing\n",
      "Processed 2500013 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 136726\n",
      "iter=0 Train=1.15223 Test=1.15402\n",
      "iter=1 Train=1.11143 Test=1.11475\n",
      "iter=2 Train=1.09046 Test=1.09506\n",
      "iter=3 Train=1.07533 Test=1.08097\n",
      "iter=4 Train=1.06291 Test=1.06942\n",
      "Time:\t\t1314 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_10m_reg.fm -e Generated/test_10m_reg.fm \\\n",
    "    --learning_rate 0.001 --learning_method SGD --hash_size -1 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 7500041 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 136726\n",
      "Preprocessing\n",
      "Processed 2500013 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 136726\n",
      "iter=0 Train=1.1351 Test=1.13817\n",
      "iter=1 Train=1.10296 Test=1.10807\n",
      "iter=2 Train=1.086 Test=1.09274\n",
      "iter=3 Train=1.07706 Test=1.08515\n",
      "iter=4 Train=1.07759 Test=1.08684\n",
      "Time:\t\t1151 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_10m_reg.fm -e Generated/test_10m_reg.fm \\\n",
    "    --learning_rate 0.003 --learning_method SGD --hash_size -1 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Попробуем с регуляризацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 7500041 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 136726\n",
      "Preprocessing\n",
      "Processed 2500013 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 136726\n",
      "iter=0 Train=1.15646 Test=1.15784\n",
      "iter=1 Train=1.094 Test=1.09629\n",
      "iter=2 Train=1.06581 Test=1.06888\n",
      "iter=3 Train=1.05545 Test=1.05912\n",
      "iter=4 Train=1.05259 Test=1.05676\n",
      "Time:\t\t1147 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_10m_reg.fm -e Generated/test_10m_reg.fm \\\n",
    "    --learning_rate 0.001 --regularization_const 0.01 --learning_method SGD --hash_size -1 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 7500041 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 136726\n",
      "Preprocessing\n",
      "Processed 2500013 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 136726\n",
      "iter=0 Train=1.15244 Test=1.15377\n",
      "iter=1 Train=1.10363 Test=1.10579\n",
      "iter=2 Train=1.07523 Test=1.07817\n",
      "iter=3 Train=1.05882 Test=1.06251\n",
      "^C\n",
      "Time:\t\t1026 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_10m_reg.fm -e Generated/test_10m_reg.fm \\\n",
    "    --learning_rate 0.001 --regularization_const 0.01 --learning_method SGD --hash_size -1 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### И с хэшинг триком\n",
    "\n",
    "Регуляризацию стало возможным ослабить, ведь и сам прием имеет некоторый такой эффект"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 7500041 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 31999\n",
      "Preprocessing\n",
      "Processed 2500013 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 31999\n",
      "iter=0 Train=1.20627 Test=1.2074\n",
      "iter=1 Train=1.18537 Test=1.18677\n",
      "iter=2 Train=1.18037 Test=1.18194\n",
      "iter=3 Train=1.18114 Test=1.1829\n",
      "iter=4 Train=1.18496 Test=1.18696\n",
      "Time:\t\t1418 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_10m_reg.fm -e Generated/test_10m_reg.fm \\\n",
    "    --learning_rate 0.001 --regularization_const 0.01 --learning_method SGD --hash_size 32000 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 7500041 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 31999\n",
      "Preprocessing\n",
      "Processed 2500013 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 31999\n",
      "iter=0 Train=1.21645 Test=1.21701\n",
      "iter=1 Train=1.19453 Test=1.1952\n",
      "iter=2 Train=1.17971 Test=1.18049\n",
      "iter=3 Train=1.16881 Test=1.16969\n",
      "iter=4 Train=1.16034 Test=1.16132\n",
      "Time:\t\t1406 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_10m_reg.fm -e Generated/test_10m_reg.fm \\\n",
    "    --learning_rate 0.0001 --regularization_const 0.0001 --learning_method SGD --hash_size 32000 -g inplace -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ALS\n",
    "\n",
    "На ALS с честными фичами без хэшинг трика запускать мне страшно\n",
    "\n",
    "Так что будем постепенно увеличивать число значений хэш функции "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 7500041 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 15999\n",
      "Preprocessing\n",
      "Processed 2500013 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 15999\n",
      "iter=0 Train=1.00607 Test=1.0069\n",
      "iter=1 Train=1.00037 Test=1.00121\n",
      "iter=2 Train=0.998275 Test=0.999098\n",
      "iter=3 Train=0.996887 Test=0.9977\n",
      "iter=4 Train=0.99592 Test=0.996725\n",
      "Time:\t\t791 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_10m_reg.fm -e Generated/test_10m_reg.fm \\\n",
    "   --pairwise 0 --regularization_const 0.0001 --learning_method ALS --hash_size 16000 -g memory -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 7500041 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 31999\n",
      "Preprocessing\n",
      "Processed 2500013 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 31999\n",
      "iter=0 Train=0.980275 Test=0.981755\n",
      "iter=1 Train=0.974717 Test=0.976171\n",
      "iter=2 Train=0.972991 Test=0.974422\n",
      "iter=3 Train=0.971827 Test=0.97324\n",
      "iter=4 Train=0.970968 Test=0.972368\n",
      "iter=5 Train=0.970318 Test=0.971708\n",
      "iter=6 Train=0.969821 Test=0.971202\n",
      "iter=7 Train=0.969439 Test=0.970813\n",
      "iter=8 Train=0.969144 Test=0.970513\n",
      "iter=9 Train=0.968916 Test=0.97028\n",
      "Time:\t\t1596 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_10m_reg.fm -e Generated/test_10m_reg.fm \\\n",
    "   --pairwise 0 --regularization_const 0.0001 --learning_method ALS --hash_size 32000 -g memory -i 10\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 7500041 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 63999\n",
      "Preprocessing\n",
      "Processed 2500013 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 63999\n",
      "iter=0 Train=0.953901 Test=0.957139\n",
      "iter=1 Train=0.947997 Test=0.951252\n",
      "iter=2 Train=0.946475 Test=0.949724\n",
      "iter=3 Train=0.94545 Test=0.94869\n",
      "iter=4 Train=0.944681 Test=0.947911\n",
      "iter=5 Train=0.944073 Test=0.947293\n",
      "iter=6 Train=0.94358 Test=0.946791\n",
      "iter=7 Train=0.943175 Test=0.946378\n",
      "iter=8 Train=0.942841 Test=0.946035\n",
      "iter=9 Train=0.942563 Test=0.94575\n",
      "Time:\t\t1497 seconds\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_10m_reg.fm -e Generated/test_10m_reg.fm \\\n",
    "   --pairwise 0 --regularization_const 0.0001 --learning_method ALS --hash_size 64000 -g memory -i 10\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Добавим парные взаимодействия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing\n",
      "Processed 7500041 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 63999\n",
      "Preprocessing\n",
      "Processed 2500013 rows\n",
      "Target from 0 to 5\n",
      "Max feature index is 63999\n",
      "iter=0 Train=0.929394 Test=0.943071\n",
      "iter=1 Train=0.914353 Test=0.930317\n",
      "iter=2 Train=0.907857 Test=0.924378\n"
     ]
    }
   ],
   "source": [
    "t_start = time.time()\n",
    "!./FM --bias true --linear true --task_type regression -t Generated/train_10m_reg.fm -e Generated/test_10m_reg.fm \\\n",
    "   --pairwise 4 --regularization_const 0.0001 --learning_method ALS --hash_size 64000 -g memory -i 5\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**В очередной раз ALS с парными фичами оставляет далеко позади остальные алгоритмы**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vowpal Wabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm2vw('Generated/train_10m_reg.fm', 'Generated/train_10m_reg.vw')\n",
    "fm2vw('Generated/test_10m_reg.fm', 'Generated/test_10m_reg.vw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_start = time.time()\n",
    "!vw Generated/train_10m_reg.vw -f VwHelpFiles/model --loss_function squared --sgd --learning_rate 0.001 -b 14 --passes 5 --cache_file VwHelpFiles/cache --quiet\n",
    "print('Training done - {0} seconds'.format(int(time.time() - t_start)))\n",
    "! vw -i VwHelpFiles/model -t Generated/test_10m_reg.vw -r VwHelpFiles/pred --quiet\n",
    "print('Start evaluation')\n",
    "print('Validation RMSE:\\t {}'.format(get_rmse('Generated/ytest_1m_user_reg', 'VwHelpFiles/pred')))\n",
    "print('Time:\\t\\t{} seconds'.format(int(time.time() - t_start)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20M Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'SourceData/ml-20m/'\n",
    "test_size = 0.25\n",
    "train, test = build_movielens(\n",
    "    folder, test_size, with_genres=True,\n",
    "    with_users_info=False, with_rated_movies=False)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_info = get_offset_stats(train, test)\n",
    "train2format(train, fm_extractor, field_info, 'Generated/train_20m_reg.fm',)\n",
    "test2format(\n",
    "    test, fm_extractor, field_info,\n",
    "    'Generated/test_20m_reg.fm',\n",
    "    'Generated/ytest_20m_reg'\n",
    ")\n",
    "!head -n 3 Generated/train_20m_reg.fm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
